{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2c2b186-9581-47ce-a6f5-74ea16e2eba0",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "---\n",
    "\n",
    "This notebook outlines the modeling process for producing a machine learning model to predict whether or not a customer will churn.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce42938-f22f-4c9b-b488-7ce7ad4f682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throughout the notebook we will use this random seed\n",
    "seed = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c9713-fe30-4629-8478-51bb828897f3",
   "metadata": {},
   "source": [
    "## Acquire and Prepare Data\n",
    "\n",
    "First let's acquire and prepare our data using the functions we previously created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "647e9f50-6bd3-4df0-b204-9e2de75d743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from env import username, password, hostname\n",
    "database_name = 'telco_churn'\n",
    "\n",
    "def get_db_url(database_name, username = username, password = password, hostname = hostname):\n",
    "    return f'mysql+pymysql://{username}:{password}@{hostname}/{database_name}'\n",
    "\n",
    "def get_telco_sql():\n",
    "    return '''\n",
    "        SELECT *\n",
    "        FROM customers\n",
    "        JOIN payment_types USING (payment_type_id)\n",
    "        JOIN internet_service_types USING (internet_service_type_id)\n",
    "        JOIN contract_types USING (contract_type_id);\n",
    "    '''\n",
    "\n",
    "def get_telco_data(use_cache = True):\n",
    "    # If the file is cached, read from the .csv file\n",
    "    if os.path.exists('telco.csv') and use_cache:\n",
    "        print('Using cache')\n",
    "        return pd.read_csv('telco.csv')\n",
    "    \n",
    "    # Otherwise read from the mysql database\n",
    "    else:\n",
    "        print('Reading from database')\n",
    "        df = pd.read_sql(get_telco_sql(), get_db_url('telco_churn'))\n",
    "        df.to_csv('telco.csv', index = False)\n",
    "        return df\n",
    "    \n",
    "def prep_telco_data(df):\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    cols_to_drop = [\n",
    "        'customer_id',\n",
    "        'contract_type_id',\n",
    "        'internet_service_type_id',\n",
    "        'payment_type_id'\n",
    "    ]\n",
    "    df = df.drop(columns = cols_to_drop)\n",
    "\n",
    "    does_not_have_zero_tenure = df.tenure != 0\n",
    "    df = df[does_not_have_zero_tenure]\n",
    "    df.total_charges = df.total_charges.astype('float')\n",
    "\n",
    "    columns = [\n",
    "        'multiple_lines',\n",
    "        'online_security',\n",
    "        'online_backup',\n",
    "        'device_protection',\n",
    "        'tech_support',\n",
    "        'streaming_tv',\n",
    "        'streaming_movies'\n",
    "    ]\n",
    "\n",
    "    for column in columns:\n",
    "        df[column] = np.where(df[column] == 'Yes', 'Yes', 'No')\n",
    "\n",
    "    categorical_cols = df.dtypes[df.dtypes == 'object'].index\n",
    "\n",
    "    dummy_df = pd.get_dummies(df[categorical_cols], dummy_na = False, drop_first = True)\n",
    "    df = pd.concat([df, dummy_df], axis = 1)\n",
    "\n",
    "    df.columns = df.columns.str.replace(' ', '_', regex = False).str.lower()\n",
    "    df.columns = df.columns.str.replace('\\(|\\)', '', regex = True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def split_data(df, stratify, random_seed = 24):\n",
    "    test_split = 0.2\n",
    "    train_validate_split = 0.3\n",
    "\n",
    "    train_validate, test = train_test_split(\n",
    "        df,\n",
    "        test_size = test_split,\n",
    "        random_state = random_seed,\n",
    "        stratify = df[stratify]\n",
    "    )\n",
    "    \n",
    "    train, validate = train_test_split(\n",
    "        train_validate,\n",
    "        test_size = train_validate_split,\n",
    "        random_state = random_seed,\n",
    "        stratify = train_validate[stratify]\n",
    "    )\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e65af3-b3c9-4225-b694-b826c0907d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3937, 40), (1688, 40), (1407, 40))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telco_customers = get_telco_data()\n",
    "telco_customers = prep_telco_data(telco_customers)\n",
    "train, validate, test = split_data(telco_customers, 'churn')\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab90c47-1731-47c1-b340-06c38769fec2",
   "metadata": {},
   "source": [
    "**We will only be using our train and validate datasets in this notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3379238f-4acd-49db-9bd5-62131a9fc15d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Establishing a Baseline Model\n",
    "\n",
    "Before we begin creating models we must first establish a baseline against which we can compare the performance of our models to determine if they meet at least the minimum standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3a216a0-6655-42a1-8896-091de18e3846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(No     2891\n",
       " Yes    1046\n",
       " Name: churn, dtype: int64,\n",
       " No     0.734315\n",
       " Yes    0.265685\n",
       " Name: churn, dtype: float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will look at the unique values of churn along with the counts of those values\n",
    "train.churn.value_counts(), train.churn.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff443ab-d455-4c34-b781-b5b567b35a1d",
   "metadata": {},
   "source": [
    "Since the most frequent value of churn is No we will establish our baseline model as one that always predicts that a customer will not churn. We can see above that such a model will have an accuracy of roughly 73%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b67ec3e-3dac-4084-887f-9f13dce5cf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No    3937\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pandas series of all \"No\"s to serve as our baseline model\n",
    "baseline = pd.Series(['No'] * train.shape[0])\n",
    "baseline.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54e53ed-206d-4524-a07a-be90b08cffaf",
   "metadata": {},
   "source": [
    "We can turn this into a function that will create the baseline model for us, we simply need to have a way of determining the most common value of our target variable and then turn that into a pandas series with that value that is the same size as our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82340f1b-b797-4a04-800e-634a71de7071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find the most common value in the churn column\n",
    "most_common_value = train.churn.mode()[0]\n",
    "most_common_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "111bcc13-2c71-4f0b-b16b-dda694825f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No    3937\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's create a series of the same size as train with only that most common value\n",
    "pd.Series([most_common_value] * train.churn.size).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d78f73-f50d-4c71-ac7b-d411061e33ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No    3937\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's turn it into a function\n",
    "\n",
    "def create_baseline_model(column):\n",
    "    most_common_value = column.mode()[0]\n",
    "    return pd.Series([most_common_value] * column.size)\n",
    "\n",
    "create_baseline_model(train.churn).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb931c-683b-4427-a602-6761b7a15181",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Measure the Performance of the Baseline\n",
    "\n",
    "Before we continue let's measure the performance of our baseline.\n",
    "\n",
    "We also want to consider which metric we should optimizing for. In this problem the cost of a false negative is far more expensive than the cost of a false positive, where a positive means that a customer does churn. The reason is because it is far more expensive to sign a new customer than it is to keep an existing one. Based on this information we should optimize for recall first and accuracy second. With this in mind we will make sure to focus on the recall score of our baseline model as well as our other models as we go through the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f607495-5408-47bd-924f-0c1ee3778725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need sklearn to measure the performance of our baseline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e1ee84e-7341-424b-acb8-b7d02e689dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7343154686309372"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train.churn, baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41075780-7039-42cb-bd26-7a0f17718f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(train.churn, baseline, pos_label = 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f50139a5-50e0-47dd-b912-18a7bbdff03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(train.churn, baseline, pos_label = 'Yes', zero_division = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb80fdc-d5d5-4b65-a2a0-04d9da3679b2",
   "metadata": {},
   "source": [
    "The baseline model scores a zero in our focus metric of recall. This is because it only predicts 'No'. In regards to comparing our models to the baseline we will look only at accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06bd8ce0-84b4-466f-b372-46a83ae479d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.734315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision  recall\n",
       "model                             \n",
       "0      0.734315        0.0     0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's turn these measurements into a function for our convenience\n",
    "\n",
    "def measure_model_performance(y_true, *y_pred, positive_label = 1):\n",
    "    scores = []\n",
    "    \n",
    "    for index, predictions in enumerate(y_pred):\n",
    "        scores.append({\n",
    "            'model' : index,\n",
    "            'accuracy' : accuracy_score(y_true, predictions),\n",
    "            'precision' : precision_score(y_true, predictions, pos_label = positive_label, zero_division = 0),\n",
    "            'recall' : recall_score(y_true, predictions, pos_label = positive_label, zero_division = 0)\n",
    "        })\n",
    "        \n",
    "    df = pd.DataFrame(scores)\n",
    "    return df.set_index('model')\n",
    "    \n",
    "measure_model_performance(train.churn, baseline, positive_label = 'Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506553e-8f2f-4605-aa08-89ea3ca0fddf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Create and Test 3 Different Models\n",
    "\n",
    "Now we will create three different machine learning models to use for predicting customer churn. We will use the following 3 types of models:\n",
    "\n",
    "- A decision tree, this will give us a simple model that can easily be understood and may provide the results we need.\n",
    "- A random forest, this will ideally give us a model that can generalize well and provide better results than the decision tree.\n",
    "- K nearest neighbors, potentially we might be able to get good results from this model.\n",
    "\n",
    "Before we begin let's separate our train and validates sets into X and y, where X is the dataset with the features we identified as drivers of churn in our explore phase and y is the churn column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd16fb23-453f-494b-aa9f-5b4ed6e42c60",
   "metadata": {},
   "source": [
    "### Split Data Into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14590ab3-943b-4d37-88ee-7261ad75301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3937 entries, 5467 to 2212\n",
      "Data columns (total 40 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   gender                              3937 non-null   object \n",
      " 1   senior_citizen                      3937 non-null   int64  \n",
      " 2   partner                             3937 non-null   object \n",
      " 3   dependents                          3937 non-null   object \n",
      " 4   tenure                              3937 non-null   int64  \n",
      " 5   phone_service                       3937 non-null   object \n",
      " 6   multiple_lines                      3937 non-null   object \n",
      " 7   online_security                     3937 non-null   object \n",
      " 8   online_backup                       3937 non-null   object \n",
      " 9   device_protection                   3937 non-null   object \n",
      " 10  tech_support                        3937 non-null   object \n",
      " 11  streaming_tv                        3937 non-null   object \n",
      " 12  streaming_movies                    3937 non-null   object \n",
      " 13  paperless_billing                   3937 non-null   object \n",
      " 14  monthly_charges                     3937 non-null   float64\n",
      " 15  total_charges                       3937 non-null   float64\n",
      " 16  churn                               3937 non-null   object \n",
      " 17  payment_type                        3937 non-null   object \n",
      " 18  internet_service_type               3937 non-null   object \n",
      " 19  contract_type                       3937 non-null   object \n",
      " 20  gender_male                         3937 non-null   uint8  \n",
      " 21  partner_yes                         3937 non-null   uint8  \n",
      " 22  dependents_yes                      3937 non-null   uint8  \n",
      " 23  phone_service_yes                   3937 non-null   uint8  \n",
      " 24  multiple_lines_yes                  3937 non-null   uint8  \n",
      " 25  online_security_yes                 3937 non-null   uint8  \n",
      " 26  online_backup_yes                   3937 non-null   uint8  \n",
      " 27  device_protection_yes               3937 non-null   uint8  \n",
      " 28  tech_support_yes                    3937 non-null   uint8  \n",
      " 29  streaming_tv_yes                    3937 non-null   uint8  \n",
      " 30  streaming_movies_yes                3937 non-null   uint8  \n",
      " 31  paperless_billing_yes               3937 non-null   uint8  \n",
      " 32  churn_yes                           3937 non-null   uint8  \n",
      " 33  payment_type_credit_card_automatic  3937 non-null   uint8  \n",
      " 34  payment_type_electronic_check       3937 non-null   uint8  \n",
      " 35  payment_type_mailed_check           3937 non-null   uint8  \n",
      " 36  internet_service_type_fiber_optic   3937 non-null   uint8  \n",
      " 37  internet_service_type_none          3937 non-null   uint8  \n",
      " 38  contract_type_one_year              3937 non-null   uint8  \n",
      " 39  contract_type_two_year              3937 non-null   uint8  \n",
      "dtypes: float64(2), int64(2), object(16), uint8(20)\n",
      "memory usage: 722.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# We will need to use encoded variables for our features\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da4772c0-f452-4491-801b-3d6954e716e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the encoded columns for contract_type and payment_type\n",
    "features = [\n",
    "    'monthly_charges',\n",
    "    'tenure',\n",
    "    'contract_type_one_year',\n",
    "    'contract_type_two_year',\n",
    "    'tech_support_yes'\n",
    "]\n",
    "\n",
    "# X_train and y_train will be used to train our models\n",
    "# X_validate and y_validate will be used to test the performance of our models\n",
    "\n",
    "X_train, y_train = train[features], train.churn\n",
    "X_validate, y_validate = validate[features], validate.churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a8db4-7b8b-4e8f-8263-5061bece24ee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Decision Tree\n",
    "\n",
    "Let's start with a decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdabb387-89a9-4355-b397-74f8756afc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4461beac-82f9-4970-b250-e5d3db66d920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=24)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll try a max_depth of 5 so we can get good results without overfitting\n",
    "model_1 = DecisionTreeClassifier(criterion = 'entropy', max_depth = 5, random_state = seed)\n",
    "model_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38b49101-0686-4ae3-91c8-e065f4f57b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     2874\n",
       "Yes    1063\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the predictions our model makes\n",
    "y_pred_model_1 = model_1.predict(X_train)\n",
    "pd.Series(y_pred_model_1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35182819-6327-4452-a2da-976794a07e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.734315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.786894</td>\n",
       "      <td>0.597366</td>\n",
       "      <td>0.607075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision    recall\n",
       "model                               \n",
       "0      0.734315   0.000000  0.000000\n",
       "1      0.786894   0.597366  0.607075"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_model_performance(y_train, baseline, y_pred_model_1, positive_label = 'Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4399325-d3d7-4981-b8b6-bc2a13dac98f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "Now let's try a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4382025a-1b0e-4aba-9806-aa6ab2fc1747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39673f9e-d2f0-430b-987d-9007734fad6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, random_state=24)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll try a max_depth of five\n",
    "model_2 = RandomForestClassifier(max_depth = 5, random_state = seed)\n",
    "model_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "313f9d8b-62ee-43c7-9382-0d9f99aedd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     3292\n",
       "Yes     645\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the predictions our model makes\n",
    "y_pred_model_2 = model_2.predict(X_train)\n",
    "pd.Series(y_pred_model_2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec007c6a-2499-477f-9ef2-65800c6f1451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.734315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.786894</td>\n",
       "      <td>0.597366</td>\n",
       "      <td>0.607075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.798070</td>\n",
       "      <td>0.694574</td>\n",
       "      <td>0.428298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision    recall\n",
       "model                               \n",
       "0      0.734315   0.000000  0.000000\n",
       "1      0.786894   0.597366  0.607075\n",
       "2      0.798070   0.694574  0.428298"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's measure the performance of this model\n",
    "measure_model_performance(y_train, baseline, y_pred_model_1, y_pred_model_2, positive_label = 'Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba920726-c563-40ea-89bb-883206eefad4",
   "metadata": {},
   "source": [
    "The performance is similar to the decision tree.\n",
    "\n",
    "---\n",
    "\n",
    "### K Nearest Neighbors\n",
    "\n",
    "Lastly let's try a k nearest neighbors model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4adac244-380e-493a-96af-a56e7e9a065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "460ba655-7ebf-4508-a32a-c104cd8abc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = KNeighborsClassifier(n_neighbors = 10, weights = 'uniform')\n",
    "model_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20aa1114-1de7-492f-900b-55be1743ae68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     3266\n",
       "Yes     671\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_model_3 = model_3.predict(X_train)\n",
    "pd.Series(y_pred_model_3).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dde91b2-e377-4d4f-83b5-32ecaf1a889c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.734315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.786894</td>\n",
       "      <td>0.597366</td>\n",
       "      <td>0.607075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.798070</td>\n",
       "      <td>0.694574</td>\n",
       "      <td>0.428298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.807214</td>\n",
       "      <td>0.713860</td>\n",
       "      <td>0.457935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision    recall\n",
       "model                               \n",
       "0      0.734315   0.000000  0.000000\n",
       "1      0.786894   0.597366  0.607075\n",
       "2      0.798070   0.694574  0.428298\n",
       "3      0.807214   0.713860  0.457935"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_model_performance(\n",
    "    y_train,\n",
    "    baseline,\n",
    "    y_pred_model_1,\n",
    "    y_pred_model_2,\n",
    "    y_pred_model_3,\n",
    "    positive_label = 'Yes'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea2a54e-9d40-431a-9e2b-261bfe61fbf2",
   "metadata": {},
   "source": [
    "The k nearest neighbors model is an improvement on the previous two models.\n",
    "\n",
    "---\n",
    "\n",
    "## Testing Our Models on Validate\n",
    "\n",
    "Now let's see how each model performs on the out of sample validate set. The best performing model here will be the one we move forward with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c364e155-77ed-40a0-b5f9-539790283aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.734005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.784360</td>\n",
       "      <td>0.595937</td>\n",
       "      <td>0.587973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.797986</td>\n",
       "      <td>0.706107</td>\n",
       "      <td>0.412027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.777844</td>\n",
       "      <td>0.637037</td>\n",
       "      <td>0.383073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision    recall\n",
       "model                               \n",
       "0      0.734005   0.000000  0.000000\n",
       "1      0.784360   0.595937  0.587973\n",
       "2      0.797986   0.706107  0.412027\n",
       "3      0.777844   0.637037  0.383073"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_model_performance(\n",
    "    y_validate,\n",
    "    create_baseline_model(y_validate),\n",
    "    model_1.predict(X_validate),\n",
    "    model_2.predict(X_validate),\n",
    "    model_3.predict(X_validate),\n",
    "    positive_label = 'Yes'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e45b2b-194c-443e-95a5-e6f852946070",
   "metadata": {},
   "source": [
    "The decision tree model has the best performance on validate with only a slight drop off in performance compared to the train set and 38% correct identification of churned customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a789d93d-04ee-429f-9d35-cbfa4d36a341",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Looking Under the Hood\n",
    "\n",
    "Before concluding let's look at how the decision tree is making its decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d42828e-eeb3-4b44-98f1-cf8087f067e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- contract_type_two_year <= 0.50\n",
      "|   |--- contract_type_one_year <= 0.50\n",
      "|   |   |--- monthly_charges <= 67.70\n",
      "|   |   |   |--- tenure <= 3.50\n",
      "|   |   |   |   |--- monthly_charges <= 24.55\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |   |   |--- monthly_charges >  24.55\n",
      "|   |   |   |   |   |--- class: Yes\n",
      "|   |   |   |--- tenure >  3.50\n",
      "|   |   |   |   |--- monthly_charges <= 25.32\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |   |   |--- monthly_charges >  25.32\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |--- monthly_charges >  67.70\n",
      "|   |   |   |--- tenure <= 6.50\n",
      "|   |   |   |   |--- tenure <= 1.50\n",
      "|   |   |   |   |   |--- class: Yes\n",
      "|   |   |   |   |--- tenure >  1.50\n",
      "|   |   |   |   |   |--- class: Yes\n",
      "|   |   |   |--- tenure >  6.50\n",
      "|   |   |   |   |--- tenure <= 29.50\n",
      "|   |   |   |   |   |--- class: Yes\n",
      "|   |   |   |   |--- tenure >  29.50\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |--- contract_type_one_year >  0.50\n",
      "|   |   |--- monthly_charges <= 98.12\n",
      "|   |   |   |--- monthly_charges <= 24.88\n",
      "|   |   |   |   |--- tenure <= 8.50\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |   |   |--- tenure >  8.50\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |   |--- monthly_charges >  24.88\n",
      "|   |   |   |   |--- tenure <= 22.50\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |   |   |--- tenure >  22.50\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |--- monthly_charges >  98.12\n",
      "|   |   |   |--- tenure <= 63.50\n",
      "|   |   |   |   |--- monthly_charges <= 111.38\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |   |   |--- monthly_charges >  111.38\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |   |--- tenure >  63.50\n",
      "|   |   |   |   |--- monthly_charges <= 117.50\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |   |   |--- monthly_charges >  117.50\n",
      "|   |   |   |   |   |--- class: Yes\n",
      "|--- contract_type_two_year >  0.50\n",
      "|   |--- monthly_charges <= 93.47\n",
      "|   |   |--- tenure <= 67.50\n",
      "|   |   |   |--- monthly_charges <= 74.70\n",
      "|   |   |   |   |--- monthly_charges <= 24.77\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |   |   |--- monthly_charges >  24.77\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |   |--- monthly_charges >  74.70\n",
      "|   |   |   |   |--- monthly_charges <= 80.50\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |   |   |--- monthly_charges >  80.50\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |--- tenure >  67.50\n",
      "|   |   |   |--- class: No\n",
      "|   |--- monthly_charges >  93.47\n",
      "|   |   |--- tenure <= 71.50\n",
      "|   |   |   |--- monthly_charges <= 94.00\n",
      "|   |   |   |   |--- tenure <= 63.50\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |   |   |--- tenure >  63.50\n",
      "|   |   |   |   |   |--- class: Yes\n",
      "|   |   |   |--- monthly_charges >  94.00\n",
      "|   |   |   |   |--- monthly_charges <= 105.95\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |   |   |--- monthly_charges >  105.95\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |--- tenure >  71.50\n",
      "|   |   |   |--- monthly_charges <= 104.53\n",
      "|   |   |   |   |--- monthly_charges <= 103.03\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |   |   |--- monthly_charges >  103.03\n",
      "|   |   |   |   |   |--- class: No\n",
      "|   |   |   |--- monthly_charges >  104.53\n",
      "|   |   |   |   |--- class: No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It's going to be difficult to read so scroll down for the summary\n",
    "print(export_text(model_1, feature_names = X_train.columns.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b27227d-d7cb-467e-acaa-f09f34ba1b80",
   "metadata": {},
   "source": [
    "This is a lot to digest so let's break down some of the key takeaways:\n",
    "- Most of the \"Yes\"s are split by contract type of month to month and monthly_charges > 67.70\n",
    "- Most of the remaining \"Yes\"s are decided by high monthly charges\n",
    "\n",
    "Likely the best recommendation to make here is whenever a customer is identified as likely to churn they should be offered a discounted rate which would make them less likely to churn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c0c2f-f064-46f6-bce0-04237a345719",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "We choose the decision tree model as our best model and in the final report notebook we will run a final check on this model to see how it performs with the test dataset and create a csv file of predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
